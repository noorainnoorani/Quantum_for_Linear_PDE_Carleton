{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is added by sphinx-gallery\n",
    "# It can be customized to whatever you like\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational Quantum Linear Solver {#vqls}\n",
    "=================================\n",
    "\n",
    "::: {.meta}\n",
    ":property=\\\"og:description\\\": Implementing the variational quantum\n",
    "linear solver to solve a system of linear equation with a quantum\n",
    "device. :property=\\\"og:image\\\":\n",
    "<https://pennylane.ai/qml/_images/vqls_zoom.png>\n",
    ":::\n",
    "\n",
    "::: {.related}\n",
    "tutorial\\_coherent\\_vqls Coherent Variational Quantum Linear Solver\n",
    ":::\n",
    "\n",
    "*Author: Andrea Mari --- Posted: 04 November 2019. Last updated: 20\n",
    "January 2021.*\n",
    "\n",
    "In this tutorial we implement a quantum algorithm known as the\n",
    "*variational quantum linear solver* (VQLS), originally introduced in\n",
    "[Bravo-Prieto et al. (2019)](https://arxiv.org/abs/1909.05820).\n",
    "\n",
    "![](../demonstrations/vqls/vqls_circuit.png){.align-center\n",
    "width=\"100.0%\"}\n",
    "\n",
    "Introduction\n",
    "------------\n",
    "\n",
    "We first define the problem and the general structure of a VQLS. As a\n",
    "second step, we consider a particular case and we solve it explicitly\n",
    "with PennyLane.\n",
    "\n",
    "### The problem\n",
    "\n",
    "We are given a $2^n \\times 2^n$ matrix $A$ which can be expressed as a\n",
    "linear combination of $L$ unitary matrices $A_0, A_1, \\dots A_{L-1}$,\n",
    "i.e.,\n",
    "\n",
    "$$A = \\sum_{l=0}^{L-1} c_l A_l,$$\n",
    "\n",
    "where $c_l$ are arbitrary complex numbers. Importantly, we assume that\n",
    "each of the unitary components $A_l$ can be efficiently implemented with\n",
    "a quantum circuit acting on $n$ qubits.\n",
    "\n",
    "We are also given a normalized complex vector in the physical form of a\n",
    "quantum state $|b\\rangle$, which can be generated by a unitary operation\n",
    "$U$ applied to the ground state of $n$ qubits. , i.e.,\n",
    "\n",
    "$$|b\\rangle = U |0\\rangle,$$\n",
    "\n",
    "where again we assume that $U$ can be efficiently implemented with a\n",
    "quantum circuit.\n",
    "\n",
    "The problem that we aim to solve is that of preparing a quantum state\n",
    "$|x\\rangle$, such that $A |x\\rangle$ is proportional to $|b\\rangle$ or,\n",
    "equivalently, such that\n",
    "\n",
    "$$|\\Psi\\rangle :=  \\frac{A |x\\rangle}{\\sqrt{\\langle x |A^\\dagger A |x\\rangle}} \\approx |b\\rangle.$$\n",
    "\n",
    "### Variational quantum linear solver\n",
    "\n",
    "The approach used in a VQLS is to approximate the solution $|x\\rangle$\n",
    "with a variational quantum circuit, i.e., a unitary circuit $V$\n",
    "depending on a finite number of classical real parameters\n",
    "$w = (w_0, w_1, \\dots)$:\n",
    "\n",
    "$$|x \\rangle = V(w) |0\\rangle.$$\n",
    "\n",
    "The parameters should be optimized in order to maximize the overlap\n",
    "between the quantum states $|\\Psi\\rangle$ and $|b\\rangle$. This suggests\n",
    "to define the following cost function:\n",
    "\n",
    "$$C_G = 1- |\\langle b | \\Psi \\rangle|^2,$$\n",
    "\n",
    "such that its minimization with respect to the variational parameters\n",
    "should lead towards the problem solution.\n",
    "\n",
    "Now we discuss two alternative methods which could be used to\n",
    "experimentally solve the minimization problem.\n",
    "\n",
    "#### First method\n",
    "\n",
    "Let us write $C_G$ more explicitly:\n",
    "\n",
    "$$C_G = 1- \\frac{ \\sum_{l, l'}  c_l c_{l'}^* \\langle 0|  V^\\dagger A_{l'}^\\dagger U \\color{blue}{|0\\rangle \\langle 0|} U^\\dagger A_l  V |0\\rangle}\n",
    "{\\sum_{l,l'} c_l c_{l'}^* \\langle 0| V^\\dagger A_{l'}^\\dagger A_l V |0\\rangle} .$$\n",
    "\n",
    "All expectation values of the previous expression could be estimated\n",
    "with a [Hadamard\n",
    "test](https://en.wikipedia.org/wiki/Hadamard_test_(quantum_computation)),\n",
    "which is a standard quantum computation technique. This method however\n",
    "might be experimentally challenging since it requires us to apply all\n",
    "the unitaries ($U^\\dagger, A_l$ and $V$) in a controlled way, i.e.,\n",
    "conditioned on the state of an ancillary qubit. A possible workaround\n",
    "for estimating the same expectation values in a simpler way has been\n",
    "proposed in Ref. \\[1\\], but will not be considered here.\n",
    "\n",
    "#### Second method\n",
    "\n",
    "The second method, which is the one used in this tutorial, is to\n",
    "minimize a \\\"local\\\" version of the cost function which is easier to\n",
    "measure and, at the same time, leads to the same optimal solution. This\n",
    "local cost function, originally proposed in Ref. \\[1\\], can be obtained\n",
    "by replacing the blue-colored projector\n",
    "$\\color{blue}{|0\\rangle\\langle 0|}$ in the previous expression with the\n",
    "following positive operator:\n",
    "\n",
    "$$\\color{blue}{P} =  \\frac{1}{2} + \\frac{1}{2n}\\sum_{j=0}^{n-1} Z_j,$$\n",
    "\n",
    "where $Z_j$ is the Pauli $Z$ operator locally applied to the $j\\rm{th}$\n",
    "qubit. This gives a new cost function:\n",
    "\n",
    "$$C_L = 1- \\frac{ \\sum_{l, l'}  c_l c_{l'}^* \\langle 0|  V^\\dagger A_{l'}^\\dagger U \\color{blue}{P} U^\\dagger A_l  V |0\\rangle}\n",
    "{\\sum_{l,l'} c_l c_{l'}^* \\langle 0| V^\\dagger A_{l'}^\\dagger A_l V |0\\rangle},$$\n",
    "\n",
    "which, as shown in Ref. \\[1\\], satisfies\n",
    "\n",
    "$$C_G \\rightarrow 0   \\Leftrightarrow C_L \\rightarrow 0,$$\n",
    "\n",
    "and so we can solve our problem by minimizing $C_L$ instead of $C_G$.\n",
    "\n",
    "Substituting the definition of $P$ into the expression for $C_L$ we get:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "C_L\n",
    "&=& \\frac{1}{2} - \\frac{1}{2n} \\frac{ \\sum_{j=0}^{n-1} \\sum_{l, l'}  c_l c_{l'}^* \\langle 0|  V^\\dagger A_{l'}^\\dagger U Z_j U^\\dagger A_l  V |0\\rangle}\n",
    "{\\sum_{l,l'} c_l c_{l'}^* \\langle 0| V^\\dagger A_{l'}^\\dagger A_l V |0\\rangle} \\\\\n",
    "&&\\\\\n",
    "&=& \\frac{1}{2} - \\frac{1}{2n} \\frac{ \\sum_{j=0}^{n-1} \\sum_{l, l'}  c_l c_{l'}^* \\mu_{l,l',j}}\n",
    "{\\sum_{l,l'} c_l c_{l'}^* \\mu_{l,l',-1}},\n",
    "\\end{aligned}$$\n",
    "\n",
    "which can be computed whenever we are able to measure the following\n",
    "coefficients\n",
    "\n",
    "$$\\mu_{l, l', j} = \\langle 0|  V^\\dagger A_{l'}^\\dagger U Z_j U^\\dagger A_l  V |0\\rangle,$$\n",
    "\n",
    "where we used the convention that if $j=-1$, $Z_{-1}$ is replaced with\n",
    "the identity.\n",
    "\n",
    "Also in this case the complex coefficients $\\mu_{l, l', j}$ can be\n",
    "experimentally measured with a Hadamard test. The corresponding quantum\n",
    "circuit is shown in the image at the top of this tutorial. Compared with\n",
    "the previous method, the main advantage of this approach is that only\n",
    "the unitary operations $A_l, A_l^\\dagger$ and $Z_j$ need to be\n",
    "controlled by an external ancillary qubit, while $V, V^\\dagger, U$ and\n",
    "$U^\\dagger$ can be directly applied to the system. This is particularly\n",
    "convenient whenever $V$ has a complex structure, e.g., if it is composed\n",
    "of many variational layers.\n",
    "\n",
    "### A simple example\n",
    "\n",
    "In this tutorial we consider the following simple example based on a\n",
    "system of 3 qubits (plus an ancilla), which is very similar to the one\n",
    "experimentally tested in Ref. \\[1\\]:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\begin{align}\n",
    "A  &=  c_0 A_0 + c_1 A_1 + c_2 A_2 = \\mathbb{I} + 0.2 X_0 Z_1 + 0.2 X_0, \\\\\n",
    "\\\\\n",
    "|b\\rangle &= U |0 \\rangle = H_0  H_1  H_2 |0\\rangle,\n",
    "\\end{align}\n",
    "\\end{aligned}$$\n",
    "\n",
    "where $Z_j, X_j, H_j$ represent the Pauli $Z$, Pauli $X$ and Hadamard\n",
    "gates applied to the qubit with index $j$.\n",
    "\n",
    "This problem is computationally quite easy since a single layer of local\n",
    "rotations is enough to generate the solution state, i.e., we can use the\n",
    "following simple ansatz:\n",
    "\n",
    "$$|x\\rangle = V(w) |0\\rangle = \\Big [  R_y(w_0) \\otimes  R_y(w_1) \\otimes  R_y(w_2) \\Big ]  H_0  H_1  H_2 |0\\rangle.$$\n",
    "\n",
    "In the code presented below we solve this particular problem by\n",
    "minimizing the local cost function $C_L$. Eventually we will compare the\n",
    "quantum solution with the classical one.\n",
    "\n",
    "General setup\n",
    "-------------\n",
    "\n",
    "This Python code requires *PennyLane* and the plotting library\n",
    "*matplotlib*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pennylane\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting of the main hyper-parameters of the model\n",
    "=================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 7  # Number of system qubits.\n",
    "n_shots = 10 ** 6  # Number of quantum measurements.\n",
    "tot_qubits = n_qubits + 1  # Addition of an ancillary qubit.\n",
    "ancilla_idx = n_qubits  # Index of the ancillary qubit (last position).\n",
    "steps = 1000  # Number of optimization steps\n",
    "eta = 1  # Learning rate\n",
    "q_delta = 0.001  # Initial spread of random quantum weights\n",
    "rng_seed = 0  # Seed for random number generator\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Circuits of the quantum linear problem\n",
    "======================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the unitary operations associated to the simple example\n",
    "presented in the introduction. Since we want to implement a Hadamard\n",
    "test, we need the unitary operations $A_j$ to be controlled by the state\n",
    "of an ancillary qubit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients of the linear combination A = c_0 A_0 + c_1 A_1 ...\n",
    "c = np.array([1.0, 0.2, 0.2])\n",
    "\n",
    "def U_b():\n",
    "    \"\"\"Unitary matrix rotating the ground state to the problem vector |b> = U_b |0>.\"\"\"\n",
    "    for idx in range(n_qubits):\n",
    "        qml.Hadamard(wires=idx)\n",
    "\n",
    "def CA(idx):\n",
    "    \"\"\"Controlled versions of the unitary components A_l of the problem matrix A.\"\"\"\n",
    "    if idx == 0:\n",
    "        # Identity operation\n",
    "        None\n",
    "\n",
    "    elif idx == 1:\n",
    "        qml.CNOT(wires=[ancilla_idx, 0])\n",
    "        qml.CZ(wires=[ancilla_idx, 1])\n",
    "\n",
    "    elif idx == 2:\n",
    "        qml.CNOT(wires=[ancilla_idx, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational quantum circuit\n",
    "===========================\n",
    "\n",
    "What follows is the variational quantum circuit that should generate the\n",
    "solution state $|x\\rangle= V(w)|0\\rangle$.\n",
    "\n",
    "The first layer of the circuit is a product of Hadamard gates preparing\n",
    "a balanced superposition of all basis states.\n",
    "\n",
    "After that, we apply a very simple variational ansatz which is just a\n",
    "single layer of qubit rotations\n",
    "$R_y(w_0) \\otimes  R_y(w_1) \\otimes  R_y(w_2)$. For solving more complex\n",
    "problems, we suggest to use more expressive circuits as, e.g., the\n",
    "PennyLane `~.StronglyEntanglingLayers`{.interpreted-text role=\"func\"}\n",
    "template.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_block(weights):\n",
    "    \"\"\"Variational circuit mapping the ground state |0> to the ansatz state |x>.\"\"\"\n",
    "    for idx in range(n_qubits):\n",
    "        qml.Hadamard(wires=idx)\n",
    "    \n",
    "    qml.StronglyEntanglingLayers(weights=weights, wires=range(n_qubits))\n",
    "    #return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "shape = qml.StronglyEntanglingLayers.shape(n_layers=4, n_wires=n_qubits)\n",
    "weights = np.random.random(size=shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hadamard test\n",
    "=============\n",
    "\n",
    "We first initialize a PennyLane device with the `default.qubit` backend.\n",
    "\n",
    "As a second step, we define a PennyLane `QNode` representing a model of\n",
    "the actual quantum computation.\n",
    "\n",
    "The circuit is based on the [Hadamard\n",
    "test](https://en.wikipedia.org/wiki/Hadamard_test_(quantum_computation))\n",
    "and will be used to estimate the coefficients $\\mu_{l,l',j}$ defined in\n",
    "the introduction. A graphical representation of this circuit is shown at\n",
    "the top of this tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_mu = qml.device(\"default.qubit\", wires=tot_qubits)\n",
    "\n",
    "@qml.qnode(dev_mu)\n",
    "def local_hadamard_test(weights, l=None, lp=None, j=None, part=None):\n",
    "\n",
    "    # First Hadamard gate applied to the ancillary qubit.\n",
    "    qml.Hadamard(wires=ancilla_idx)\n",
    "\n",
    "    # For estimating the imaginary part of the coefficient \"mu\", we must add a \"-i\"\n",
    "    # phase gate.\n",
    "    if part == \"Im\" or part == \"im\":\n",
    "        qml.PhaseShift(-np.pi / 2, wires=ancilla_idx)\n",
    "\n",
    "    # Variational circuit generating a guess for the solution vector |x>\n",
    "    variational_block(weights)\n",
    "\n",
    "    # Controlled application of the unitary component A_l of the problem matrix A.\n",
    "    CA(l)\n",
    "\n",
    "    # Adjoint of the unitary U_b associated to the problem vector |b>. \n",
    "    # In this specific example Adjoint(U_b) = U_b.\n",
    "    U_b()\n",
    "\n",
    "    # Controlled Z operator at position j. If j = -1, apply the identity.\n",
    "    if j != -1:\n",
    "        qml.CZ(wires=[ancilla_idx, j])\n",
    "\n",
    "    # Unitary U_b associated to the problem vector |b>.\n",
    "    U_b()\n",
    "\n",
    "    # Controlled application of Adjoint(A_lp).\n",
    "    # In this specific example Adjoint(A_lp) = A_lp.\n",
    "    CA(lp)\n",
    "\n",
    "    # Second Hadamard gate applied to the ancillary qubit.\n",
    "    qml.Hadamard(wires=ancilla_idx)\n",
    "    \n",
    "    \n",
    "    #print(weights)\n",
    "    \n",
    "    \n",
    "    # Expectation value of Z for the ancillary qubit.\n",
    "    return qml.expval(qml.PauliZ(wires=ancilla_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the real and imaginary parts of $\\mu_{l,l',j}$, one needs to run\n",
    "the previous quantum circuit with and without a phase-shift of the\n",
    "ancillary qubit. This is automatically done by the following function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu(weights, l=None, lp=None, j=None):\n",
    "    \"\"\"Generates the coefficients to compute the \"local\" cost function C_L.\"\"\"\n",
    "\n",
    "    mu_real = local_hadamard_test(weights, l=l, lp=lp, j=j, part=\"Re\")\n",
    "    mu_imag = local_hadamard_test(weights, l=l, lp=lp, j=j, part=\"Im\")\n",
    "\n",
    "    return mu_real + 1.0j * mu_imag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local cost function\n",
    "===================\n",
    "\n",
    "Let us first define a function for estimating\n",
    "$\\langle x| A^\\dagger A|x\\rangle$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi_norm(weights):\n",
    "    \"\"\"Returns the normalization constant <psi|psi>, where |psi> = A |x>.\"\"\"\n",
    "    norm = 0.0\n",
    "\n",
    "    for l in range(0, len(c)):\n",
    "        for lp in range(0, len(c)):\n",
    "            norm = norm + c[l] * np.conj(c[lp]) * mu(weights, l, lp, -1)\n",
    "\n",
    "    return abs(norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally define the cost function of our minimization problem. We\n",
    "use the analytical expression of $C_L$ in terms of the coefficients\n",
    "$\\mu_{l,l',j}$ given in the introduction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_loc(weights):\n",
    "    \"\"\"Local version of the cost function. Tends to zero when A|x> is proportional to |b>.\"\"\"\n",
    "    mu_sum = 0.0\n",
    "\n",
    "    for l in range(0, len(c)):\n",
    "        for lp in range(0, len(c)):\n",
    "            for j in range(0, n_qubits):\n",
    "                mu_sum = mu_sum + c[l] * np.conj(c[lp]) * mu(weights, l, lp, j)\n",
    "\n",
    "    mu_sum = abs(mu_sum)\n",
    "\n",
    "    # Cost function C_L\n",
    "    return 0.5 - 0.5 * mu_sum / (n_qubits * psi_norm(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational optimization\n",
    "========================\n",
    "\n",
    "We first initialize the variational weights with random parameters (with\n",
    "a fixed seed).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(rng_seed)\n",
    "shape = (1, n_qubits, 2)\n",
    "w = q_delta * np.random.random(size=shape)\n",
    "#w = q_delta * np.random.randn(size = shape, requires_grad=True)\n",
    "#w = tensor([0.00176405, 0.00040016, 0.00097874])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To minimize the cost function we use the gradient-descent optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = qml.GradientDescentOptimizer(eta)\n",
    "#opt = qml.AdagradOptimizer(eta)\n",
    "#opt = qml.AdamOptimizer(eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to perform the optimization loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience = 0\n",
      "Step   0       Cost_L = 4.79e-01\n",
      "patience = 0\n",
      "Step   1       Cost_L = 4.67e-01\n",
      "patience = 0\n",
      "Step   2       Cost_L = 4.56e-01\n",
      "patience = 0\n",
      "Step   3       Cost_L = 4.46e-01\n",
      "patience = 0\n",
      "Step   4       Cost_L = 4.38e-01\n",
      "patience = 0\n",
      "Step   5       Cost_L = 4.30e-01\n",
      "patience = 0\n",
      "Step   6       Cost_L = 4.24e-01\n",
      "patience = 0\n",
      "Step   7       Cost_L = 4.18e-01\n",
      "patience = 0\n",
      "Step   8       Cost_L = 4.12e-01\n",
      "patience = 0\n",
      "Step   9       Cost_L = 4.07e-01\n",
      "patience = 0\n",
      "Step  10       Cost_L = 4.03e-01\n",
      "patience = 0\n",
      "Step  11       Cost_L = 3.98e-01\n",
      "patience = 0\n",
      "Step  12       Cost_L = 3.93e-01\n",
      "patience = 0\n",
      "Step  13       Cost_L = 3.89e-01\n",
      "patience = 0\n",
      "Step  14       Cost_L = 3.84e-01\n",
      "patience = 0\n",
      "Step  15       Cost_L = 3.80e-01\n",
      "patience = 0\n",
      "Step  16       Cost_L = 3.75e-01\n",
      "patience = 0\n",
      "Step  17       Cost_L = 3.71e-01\n",
      "patience = 0\n",
      "Step  18       Cost_L = 3.66e-01\n",
      "patience = 0\n",
      "Step  19       Cost_L = 3.61e-01\n",
      "patience = 0\n",
      "Step  20       Cost_L = 3.57e-01\n",
      "patience = 0\n",
      "Step  21       Cost_L = 3.52e-01\n",
      "patience = 0\n",
      "Step  22       Cost_L = 3.47e-01\n",
      "patience = 0\n",
      "Step  23       Cost_L = 3.42e-01\n",
      "patience = 0\n",
      "Step  24       Cost_L = 3.38e-01\n",
      "patience = 0\n",
      "Step  25       Cost_L = 3.33e-01\n",
      "patience = 0\n",
      "Step  26       Cost_L = 3.29e-01\n",
      "patience = 0\n",
      "Step  27       Cost_L = 3.25e-01\n",
      "patience = 0\n",
      "Step  28       Cost_L = 3.21e-01\n",
      "patience = 0\n",
      "Step  29       Cost_L = 3.18e-01\n",
      "patience = 0\n",
      "Step  30       Cost_L = 3.14e-01\n",
      "patience = 0\n",
      "Step  31       Cost_L = 3.11e-01\n",
      "patience = 0\n",
      "Step  32       Cost_L = 3.08e-01\n",
      "patience = 0\n",
      "Step  33       Cost_L = 3.05e-01\n",
      "patience = 0\n",
      "Step  34       Cost_L = 3.02e-01\n",
      "patience = 0\n",
      "Step  35       Cost_L = 2.99e-01\n",
      "patience = 0\n",
      "Step  36       Cost_L = 2.97e-01\n",
      "patience = 0\n",
      "Step  37       Cost_L = 2.95e-01\n",
      "patience = 0\n",
      "Step  38       Cost_L = 2.92e-01\n",
      "patience = 0\n",
      "Step  39       Cost_L = 2.90e-01\n",
      "patience = 0\n",
      "Step  40       Cost_L = 2.88e-01\n",
      "patience = 0\n",
      "Step  41       Cost_L = 2.86e-01\n",
      "patience = 0\n",
      "Step  42       Cost_L = 2.84e-01\n",
      "patience = 0\n",
      "Step  43       Cost_L = 2.82e-01\n",
      "patience = 0\n",
      "Step  44       Cost_L = 2.79e-01\n",
      "patience = 0\n",
      "Step  45       Cost_L = 2.77e-01\n",
      "patience = 0\n",
      "Step  46       Cost_L = 2.75e-01\n",
      "patience = 0\n",
      "Step  47       Cost_L = 2.73e-01\n",
      "patience = 0\n",
      "Step  48       Cost_L = 2.71e-01\n",
      "patience = 0\n",
      "Step  49       Cost_L = 2.69e-01\n",
      "patience = 0\n",
      "Step  50       Cost_L = 2.67e-01\n",
      "patience = 0\n",
      "Step  51       Cost_L = 2.65e-01\n",
      "patience = 0\n",
      "Step  52       Cost_L = 2.63e-01\n",
      "patience = 0\n",
      "Step  53       Cost_L = 2.61e-01\n",
      "patience = 0\n",
      "Step  54       Cost_L = 2.58e-01\n",
      "patience = 0\n",
      "Step  55       Cost_L = 2.56e-01\n",
      "patience = 0\n",
      "Step  56       Cost_L = 2.53e-01\n",
      "patience = 0\n",
      "Step  57       Cost_L = 2.50e-01\n",
      "patience = 0\n",
      "Step  58       Cost_L = 2.47e-01\n",
      "patience = 0\n",
      "Step  59       Cost_L = 2.44e-01\n",
      "patience = 0\n",
      "Step  60       Cost_L = 2.40e-01\n",
      "patience = 0\n",
      "Step  61       Cost_L = 2.37e-01\n",
      "patience = 0\n",
      "Step  62       Cost_L = 2.33e-01\n",
      "patience = 0\n",
      "Step  63       Cost_L = 2.29e-01\n",
      "patience = 0\n",
      "Step  64       Cost_L = 2.25e-01\n",
      "patience = 0\n",
      "Step  65       Cost_L = 2.20e-01\n",
      "patience = 0\n",
      "Step  66       Cost_L = 2.16e-01\n",
      "patience = 0\n",
      "Step  67       Cost_L = 2.12e-01\n",
      "patience = 0\n",
      "Step  68       Cost_L = 2.07e-01\n",
      "patience = 0\n",
      "Step  69       Cost_L = 2.03e-01\n",
      "patience = 0\n",
      "Step  70       Cost_L = 1.99e-01\n",
      "patience = 0\n",
      "Step  71       Cost_L = 1.95e-01\n",
      "patience = 0\n",
      "Step  72       Cost_L = 1.91e-01\n",
      "patience = 0\n",
      "Step  73       Cost_L = 1.87e-01\n",
      "patience = 0\n",
      "Step  74       Cost_L = 1.83e-01\n",
      "patience = 0\n",
      "Step  75       Cost_L = 1.80e-01\n",
      "patience = 0\n",
      "Step  76       Cost_L = 1.76e-01\n",
      "patience = 0\n",
      "Step  77       Cost_L = 1.73e-01\n",
      "patience = 0\n",
      "Step  78       Cost_L = 1.69e-01\n",
      "patience = 0\n",
      "Step  79       Cost_L = 1.66e-01\n",
      "patience = 0\n",
      "Step  80       Cost_L = 1.62e-01\n",
      "patience = 0\n",
      "Step  81       Cost_L = 1.59e-01\n",
      "patience = 0\n",
      "Step  82       Cost_L = 1.55e-01\n",
      "patience = 0\n",
      "Step  83       Cost_L = 1.51e-01\n",
      "patience = 0\n",
      "Step  84       Cost_L = 1.47e-01\n",
      "patience = 0\n",
      "Step  85       Cost_L = 1.43e-01\n",
      "patience = 0\n",
      "Step  86       Cost_L = 1.39e-01\n",
      "patience = 0\n",
      "Step  87       Cost_L = 1.34e-01\n",
      "patience = 0\n",
      "Step  88       Cost_L = 1.30e-01\n",
      "patience = 0\n",
      "Step  89       Cost_L = 1.26e-01\n",
      "patience = 0\n",
      "Step  90       Cost_L = 1.22e-01\n",
      "patience = 0\n",
      "Step  91       Cost_L = 1.17e-01\n",
      "patience = 0\n",
      "Step  92       Cost_L = 1.13e-01\n",
      "patience = 0\n",
      "Step  93       Cost_L = 1.10e-01\n",
      "patience = 0\n",
      "Step  94       Cost_L = 1.06e-01\n",
      "patience = 0\n",
      "Step  95       Cost_L = 1.03e-01\n",
      "patience = 0\n",
      "Step  96       Cost_L = 9.95e-02\n",
      "patience = 0\n",
      "Step  97       Cost_L = 9.66e-02\n",
      "patience = 0\n",
      "Step  98       Cost_L = 9.39e-02\n",
      "patience = 0\n",
      "Step  99       Cost_L = 9.15e-02\n",
      "patience = 0\n",
      "Step 100       Cost_L = 8.93e-02\n",
      "patience = 0\n",
      "Step 101       Cost_L = 8.73e-02\n",
      "patience = 0\n",
      "Step 102       Cost_L = 8.55e-02\n",
      "patience = 0\n",
      "Step 103       Cost_L = 8.40e-02\n",
      "patience = 0\n",
      "Step 104       Cost_L = 8.26e-02\n",
      "patience = 0\n",
      "Step 105       Cost_L = 8.13e-02\n",
      "patience = 0\n",
      "Step 106       Cost_L = 8.03e-02\n",
      "patience = 0\n",
      "Step 107       Cost_L = 7.93e-02\n",
      "patience = 0\n",
      "Step 108       Cost_L = 7.85e-02\n",
      "patience = 0\n",
      "Step 109       Cost_L = 7.78e-02\n",
      "patience = 0\n",
      "Step 110       Cost_L = 7.72e-02\n",
      "patience = 0\n",
      "Step 111       Cost_L = 7.66e-02\n",
      "patience = 0\n",
      "Step 112       Cost_L = 7.61e-02\n",
      "patience = 0\n",
      "Step 113       Cost_L = 7.57e-02\n",
      "patience = 0\n",
      "Step 114       Cost_L = 7.53e-02\n",
      "patience = 0\n",
      "Step 115       Cost_L = 7.50e-02\n",
      "patience = 0\n",
      "Step 116       Cost_L = 7.47e-02\n",
      "patience = 0\n",
      "Step 117       Cost_L = 7.45e-02\n",
      "patience = 0\n",
      "Step 118       Cost_L = 7.42e-02\n",
      "patience = 0\n",
      "Step 119       Cost_L = 7.40e-02\n",
      "patience = 0\n",
      "Step 120       Cost_L = 7.39e-02\n",
      "patience = 0\n",
      "Step 121       Cost_L = 7.37e-02\n",
      "patience = 0\n",
      "Step 122       Cost_L = 7.35e-02\n",
      "patience = 0\n",
      "Step 123       Cost_L = 7.34e-02\n",
      "patience = 0\n",
      "Step 124       Cost_L = 7.33e-02\n",
      "patience = 0\n",
      "Step 125       Cost_L = 7.32e-02\n",
      "patience = 0\n",
      "Step 126       Cost_L = 7.31e-02\n",
      "patience = 0\n",
      "Step 127       Cost_L = 7.30e-02\n",
      "patience = 0\n",
      "Step 128       Cost_L = 7.29e-02\n",
      "patience = 0\n",
      "Step 129       Cost_L = 7.29e-02\n",
      "patience = 0\n",
      "Step 130       Cost_L = 7.28e-02\n",
      "patience = 0\n",
      "Step 131       Cost_L = 7.27e-02\n",
      "patience = 0\n",
      "Step 132       Cost_L = 7.27e-02\n",
      "patience = 0\n",
      "Step 133       Cost_L = 7.26e-02\n",
      "patience = 0\n",
      "Step 134       Cost_L = 7.26e-02\n",
      "patience = 0\n",
      "Step 135       Cost_L = 7.25e-02\n",
      "patience = 0\n",
      "Step 136       Cost_L = 7.25e-02\n",
      "patience = 0\n",
      "Step 137       Cost_L = 7.24e-02\n",
      "patience = 0\n",
      "Step 138       Cost_L = 7.24e-02\n",
      "patience = 0\n",
      "Step 139       Cost_L = 7.24e-02\n",
      "patience = 0\n",
      "Step 140       Cost_L = 7.23e-02\n",
      "patience = 0\n",
      "Step 141       Cost_L = 7.23e-02\n",
      "patience = 0\n",
      "Step 142       Cost_L = 7.23e-02\n",
      "patience = 0\n",
      "Step 143       Cost_L = 7.23e-02\n",
      "patience = 0\n",
      "Step 144       Cost_L = 7.22e-02\n",
      "patience = 0\n",
      "Step 145       Cost_L = 7.22e-02\n",
      "patience = 0\n",
      "Step 146       Cost_L = 7.22e-02\n",
      "patience = 0\n",
      "Step 147       Cost_L = 7.22e-02\n",
      "patience = 0\n",
      "Step 148       Cost_L = 7.21e-02\n",
      "patience = 0\n",
      "Step 149       Cost_L = 7.21e-02\n",
      "patience = 0\n",
      "Step 150       Cost_L = 7.21e-02\n",
      "patience = 0\n",
      "Step 151       Cost_L = 7.21e-02\n",
      "patience = 0\n",
      "Step 152       Cost_L = 7.21e-02\n",
      "patience = 0\n",
      "Step 153       Cost_L = 7.21e-02\n",
      "patience = 0\n",
      "Step 154       Cost_L = 7.20e-02\n",
      "patience = 0\n",
      "Step 155       Cost_L = 7.20e-02\n",
      "patience = 0\n",
      "Step 156       Cost_L = 7.20e-02\n",
      "patience = 0\n",
      "Step 157       Cost_L = 7.20e-02\n",
      "patience = 0\n",
      "Step 158       Cost_L = 7.20e-02\n",
      "patience = 0\n",
      "Step 159       Cost_L = 7.20e-02\n",
      "patience = 0\n",
      "Step 160       Cost_L = 7.20e-02\n",
      "patience = 0\n",
      "Step 161       Cost_L = 7.19e-02\n",
      "patience = 0\n",
      "Step 162       Cost_L = 7.19e-02\n",
      "patience = 0\n",
      "Step 163       Cost_L = 7.19e-02\n",
      "patience = 0\n",
      "Step 164       Cost_L = 7.19e-02\n",
      "patience = 0\n",
      "Step 165       Cost_L = 7.19e-02\n",
      "patience = 0\n",
      "Step 166       Cost_L = 7.19e-02\n",
      "patience = 0\n",
      "Step 167       Cost_L = 7.19e-02\n",
      "patience = 0\n",
      "Step 168       Cost_L = 7.19e-02\n",
      "patience = 0\n",
      "Step 169       Cost_L = 7.19e-02\n",
      "patience = 0\n",
      "Step 170       Cost_L = 7.19e-02\n",
      "patience = 0\n",
      "Step 171       Cost_L = 7.18e-02\n",
      "patience = 0\n",
      "Step 172       Cost_L = 7.18e-02\n",
      "patience = 0\n",
      "Step 173       Cost_L = 7.18e-02\n",
      "patience = 0\n",
      "Step 174       Cost_L = 7.18e-02\n",
      "patience = 0\n",
      "Step 175       Cost_L = 7.18e-02\n",
      "patience = 0\n",
      "Step 176       Cost_L = 7.18e-02\n",
      "patience = 0\n",
      "Step 177       Cost_L = 7.18e-02\n",
      "patience = 0\n",
      "Step 178       Cost_L = 7.18e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience = 0\n",
      "Step 179       Cost_L = 7.18e-02\n",
      "patience = 0\n",
      "Step 180       Cost_L = 7.18e-02\n",
      "patience = 0\n",
      "Step 181       Cost_L = 7.18e-02\n",
      "patience = 0\n",
      "Step 182       Cost_L = 7.18e-02\n",
      "patience = 0\n",
      "Step 183       Cost_L = 7.18e-02\n",
      "patience = 0\n",
      "Step 184       Cost_L = 7.18e-02\n",
      "patience = 0\n",
      "Step 185       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 186       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 187       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 188       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 189       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 190       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 191       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 192       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 193       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 194       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 195       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 196       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 197       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 198       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 199       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 200       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 201       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 202       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 203       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 204       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 205       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 206       Cost_L = 7.17e-02\n",
      "patience = 0\n",
      "Step 207       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 208       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 209       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 210       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 211       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 212       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 213       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 214       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 215       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 216       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 217       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 218       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 219       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 220       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 221       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 222       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 223       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 224       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 225       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 226       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 227       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 228       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 229       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 230       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 231       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 232       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 233       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 234       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 235       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 236       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 237       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 238       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 239       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 240       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 241       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 242       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 243       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 244       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 245       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 246       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 247       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 248       Cost_L = 7.16e-02\n",
      "patience = 0\n",
      "Step 249       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 250       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 251       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 252       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 253       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 254       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 255       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 256       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 257       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 258       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 259       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 260       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 261       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 262       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 263       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 264       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 265       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 266       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 267       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 268       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 269       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 270       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 271       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 272       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 273       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 274       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 275       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 276       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 277       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 278       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 279       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 280       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 281       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 282       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 283       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 284       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 285       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 286       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 287       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 288       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 289       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 290       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 291       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 292       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 293       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 294       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 295       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 296       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 297       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 298       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 299       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 300       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 301       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 302       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 303       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 304       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 305       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 306       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 307       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 308       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 309       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 310       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 311       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 312       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 313       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 314       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 315       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 316       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 317       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 318       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 319       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 320       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 321       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 322       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 323       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 324       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 325       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 326       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 327       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 328       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 329       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 330       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 331       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 332       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 333       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 334       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 335       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 336       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 337       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 338       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 339       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 340       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 341       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 342       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 343       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 344       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 345       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 346       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 347       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 348       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 349       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 350       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 351       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 352       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 353       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 354       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 355       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 356       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 357       Cost_L = 7.15e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience = 0\n",
      "Step 358       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 359       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 360       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 361       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 362       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 363       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 364       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 365       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 366       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 367       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 368       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 369       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 370       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 371       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 372       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 373       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 374       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 375       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 376       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 377       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 378       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 379       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 380       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 381       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 382       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 383       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 384       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 385       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 386       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 387       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 388       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 389       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 390       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 391       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 392       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 393       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 394       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 395       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 396       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 397       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 398       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 399       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 400       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 401       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 402       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 403       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 404       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 405       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 406       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 407       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 408       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 409       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 410       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 411       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 412       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 413       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 414       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 415       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 416       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 417       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 418       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 419       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 420       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 421       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 422       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 423       Cost_L = 7.15e-02\n",
      "patience = 0\n",
      "Step 424       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 425       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 426       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 427       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 428       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 429       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 430       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 431       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 432       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 433       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 434       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 435       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 436       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 437       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 438       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 439       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 440       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 441       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 442       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 443       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 444       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 445       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 446       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 447       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 448       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 449       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 450       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 451       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 452       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 453       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 454       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 455       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 456       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 457       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 458       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 459       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 460       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 461       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 462       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 463       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 464       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 465       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 466       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 467       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 468       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 469       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 470       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 471       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 472       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 473       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 474       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 475       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 476       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 477       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 478       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 479       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 480       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 481       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 482       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 483       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 484       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 485       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 486       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 487       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 488       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 489       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 490       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 491       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 492       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 493       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 494       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 495       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 496       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 497       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 498       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 499       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 500       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 501       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 502       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 503       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 504       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 505       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 506       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 507       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 508       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 509       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 510       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 511       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 512       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 513       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 514       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 515       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 516       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 517       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 518       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 519       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 520       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 521       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 522       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 523       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 524       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 525       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 526       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 527       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 528       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 529       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 530       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 531       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 532       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 533       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 534       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 535       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 536       Cost_L = 7.14e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience = 0\n",
      "Step 537       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 538       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 539       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 540       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 541       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 542       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 543       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 544       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 545       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 546       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 547       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 548       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 549       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 550       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 551       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 552       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 553       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 554       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 555       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 556       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 557       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 558       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 559       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 560       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 561       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 562       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 563       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 564       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 565       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 566       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 567       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 568       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 569       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 570       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 571       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 572       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 573       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 574       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 575       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 576       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 577       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 578       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 579       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 580       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 581       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 582       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 583       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 584       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 585       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 586       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 587       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 588       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 589       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 590       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 591       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 592       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 593       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 594       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 595       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 596       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 597       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 598       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 599       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 600       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 601       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 602       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 603       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 604       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 605       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 606       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 607       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 608       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 609       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 610       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 611       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 612       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 613       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 614       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 615       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 616       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 617       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 618       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 619       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 620       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 621       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 622       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 623       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 624       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 625       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 626       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 627       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 628       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 629       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 630       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 631       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 632       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 633       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 634       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 635       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 636       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 637       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 638       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 639       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 640       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 641       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 642       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 643       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 644       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 645       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 646       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 647       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 648       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 649       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 650       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 651       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 652       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 653       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 654       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 655       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 656       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 657       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 658       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 659       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 660       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 661       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 662       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 663       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 664       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 665       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 666       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 667       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 668       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 669       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 670       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 671       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 672       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 673       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 674       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 675       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 676       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 677       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 678       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 679       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 680       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 681       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 682       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 683       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 684       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 685       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 686       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 687       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 688       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 689       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 690       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 691       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 692       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 693       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 694       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 695       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 696       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 697       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 698       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 699       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 700       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 701       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 702       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 703       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 704       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 705       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 706       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 707       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 708       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 709       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 710       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 711       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 712       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 713       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 714       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 715       Cost_L = 7.14e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience = 0\n",
      "Step 716       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 717       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 718       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 719       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 720       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 721       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 722       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 723       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 724       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 725       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 726       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 727       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 728       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 729       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 730       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 731       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 732       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 733       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 734       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 735       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 736       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 737       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 738       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 739       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 740       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 741       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 742       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 743       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 744       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 745       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 746       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 747       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 748       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 749       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 750       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 751       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 752       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 753       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 754       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 755       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 756       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 757       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 758       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 759       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 760       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 761       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 762       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 763       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 764       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 765       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 766       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 767       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 768       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 769       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 770       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 771       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 772       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 773       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 774       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 775       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 776       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 777       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 778       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 779       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 780       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 781       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 782       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 783       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 784       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 785       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 786       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 787       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 788       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 789       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 790       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 791       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 792       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 793       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 794       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 795       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 796       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 797       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 798       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 799       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 800       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 801       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 802       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 803       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 804       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 805       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 806       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 807       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 808       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 809       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 810       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 811       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 812       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 813       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 814       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 815       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 816       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 817       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 818       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 819       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 820       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 821       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 822       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 823       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 824       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 825       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 826       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 827       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 828       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 829       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 830       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 831       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 832       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 833       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 834       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 835       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 836       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 837       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 838       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 839       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 840       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 841       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 842       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 843       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 844       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 845       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 846       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 847       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 848       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 849       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 850       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 851       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 852       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 853       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 854       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 855       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 856       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 857       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 858       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 859       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 860       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 861       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 862       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 863       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 864       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 865       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 866       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 867       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 868       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 869       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 870       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 871       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 872       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 873       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 874       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 875       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 876       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 877       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 878       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 879       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 880       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 881       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 882       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 883       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 884       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 885       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 886       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 887       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 888       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 889       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 890       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 891       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 892       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 893       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 894       Cost_L = 7.14e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience = 0\n",
      "Step 895       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 896       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 897       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 898       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 899       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 900       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 901       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 902       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 903       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 904       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 905       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 906       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 907       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 908       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 909       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 910       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 911       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 912       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 913       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 914       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 915       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 916       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 917       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 918       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 919       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 920       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 921       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 922       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 923       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 924       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 925       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 926       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 927       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 928       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 929       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 930       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 931       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 932       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 933       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 934       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 935       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 936       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 937       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 938       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 939       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 940       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 941       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 942       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 943       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 944       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 945       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 946       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 947       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 948       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 949       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 950       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 951       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 952       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 953       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 954       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 955       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 956       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 957       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 958       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 959       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 960       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 961       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 962       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 963       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 964       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 965       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 966       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 967       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 968       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 969       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 970       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 971       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 972       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 973       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 974       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 975       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 976       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 977       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 978       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 979       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 980       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 981       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 982       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 983       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 984       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 985       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 986       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 987       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 988       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 989       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 990       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 991       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 992       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 993       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 994       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 995       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 996       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 997       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 998       Cost_L = 7.14e-02\n",
      "patience = 0\n",
      "Step 999       Cost_L = 7.14e-02\n"
     ]
    }
   ],
   "source": [
    "cost_history = []\n",
    "lowest_cost = 1000\n",
    "current_patience = 0\n",
    "best_weights = 0\n",
    "\n",
    "for it in range(steps):\n",
    "    w, cost = opt.step_and_cost(cost_loc, w)\n",
    "    print(\"patience = \" + str(current_patience))\n",
    "    print(\"Step {:3d}       Cost_L = {:.2e}\".format(it, cost))\n",
    "    \n",
    "    if cost > lowest_cost:\n",
    "        current_patience = current_patience + 1\n",
    "        best_weights = w\n",
    "    else:\n",
    "        lowest_cost = cost\n",
    "        current_patience = 0\n",
    "    \n",
    "    cost_history.append(cost)\n",
    "    \n",
    "    if current_patience == patience:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the cost function with respect to the optimization steps. We\n",
    "remark that this is not an abstract mathematical quantity since it also\n",
    "represents a bound for the error between the generated state and the\n",
    "exact solution of the problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use(\"seaborn\")\n",
    "plt.plot(cost_history, \"g\")\n",
    "plt.ylabel(\"Cost function\")\n",
    "plt.xlabel(\"Optimization steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of quantum and classical results\n",
    "===========================================\n",
    "\n",
    "Since the specific problem considered in this tutorial has a small size,\n",
    "we can also solve it in a classical way and then compare the results\n",
    "with our quantum solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classical algorithm\n",
    "===================\n",
    "\n",
    "To solve the problem in a classical way, we use the explicit matrix\n",
    "representation in terms of numerical NumPy arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = np.identity(2)\n",
    "Z = np.array([[1, 0], [0, -1]])\n",
    "X = np.array([[0, 1], [1, 0]])\n",
    "\n",
    "A_0 = np.identity(128)\n",
    "A_1 = np.kron(np.kron(np.kron(np.kron(np.kron(np.kron(X, Z), Id),Id),Id),Id),Id)\n",
    "A_2 = np.kron(np.kron(np.kron(np.kron(np.kron(np.kron(X, Id),Id),Id),Id),Id),Id)\n",
    "A_3 = np.kron(np.kron(np.kron(np.kron(np.kron(np.kron(Z, Z), Id),Id),Id),Id),Id)\n",
    "\n",
    "#Ax = b\n",
    "A = 1 * A_0 + 0.2 * A_1 + 0.2 * A_2 \n",
    "b = np.ones(128) / np.sqrt(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the explicit values of $A$ and $b$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = \n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "b = \n",
      " [0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835 0.08838835\n",
      " 0.08838835 0.08838835]\n"
     ]
    }
   ],
   "source": [
    "print(\"A = \\n\", A)\n",
    "print(\"b = \\n\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution can be computed via a matrix inversion:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_inv = np.linalg.inv(A)\n",
    "x = np.dot(A_inv, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in order to compare x with the quantum state $|x\\rangle$, we\n",
    "normalize and square its elements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_probs = (x / np.linalg.norm(x)) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation of the quantum solution\n",
    "===================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the variational weights `w` that we have previously optimized, we\n",
    "can generate the quantum state $|x\\rangle$. By measuring $|x\\rangle$ in\n",
    "the computational basis we can estimate the probability of each basis\n",
    "state.\n",
    "\n",
    "For this task, we initialize a new PennyLane device and define the\n",
    "associated *qnode* circuit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_x = qml.device(\"default.qubit\", wires=n_qubits, shots=n_shots)\n",
    "\n",
    "@qml.qnode(dev_x)\n",
    "def prepare_and_sample(weights):\n",
    "\n",
    "    # Variational circuit generating a guess for the solution vector |x>\n",
    "    variational_block(weights)\n",
    "\n",
    "    # We assume that the system is measured in the computational basis.\n",
    "    # then sampling the device will give us a value of 0 or 1 for each qubit (n_qubits)\n",
    "    # this will be repeated for the total number of shots provided (n_shots)\n",
    "    return qml.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 7.57197298e-02 -1.17029873e-05 -7.55129223e-02]\n",
      "  [ 5.17075694e-02 -1.54767622e-05 -5.17010614e-02]\n",
      "  [ 6.94599190e-01  4.47920598e-01  8.24729581e-01]\n",
      "  [ 1.00852054e+00  3.19419929e-01  5.39172082e-01]\n",
      "  [ 1.31460641e-01 -2.16121311e-03 -1.31460131e-01]\n",
      "  [ 3.64408715e-03  1.57024119e+00  1.52340383e-01]\n",
      "  [ 5.06487707e-01  2.19735043e-01 -2.61346258e-01]]\n",
      "\n",
      " [[ 1.34818747e-01 -5.77520497e-06 -1.34828201e-01]\n",
      "  [ 7.27716127e-01  4.87732593e-01  7.81218835e-01]\n",
      "  [-1.36643031e-01  1.80382329e-06 -3.66626508e-01]\n",
      "  [ 8.50884501e-01  2.22138639e-01  7.07606260e-01]\n",
      "  [-3.16998019e-02 -1.46213176e-03  4.25032090e-01]\n",
      "  [ 5.71606220e-01  5.33976876e-01 -2.06123758e-01]\n",
      "  [ 1.80085163e+00  3.59281135e-03  1.34078022e+00]]\n",
      "\n",
      " [[ 2.90737553e-08  1.57084344e+00  4.57413166e-03]\n",
      "  [ 2.37409618e-01 -2.84815851e-05 -2.37409637e-01]\n",
      "  [ 2.76839074e-01  7.24900893e-05 -2.89179328e-01]\n",
      "  [ 9.38831975e-02 -3.12058678e-07 -9.84566903e-02]\n",
      "  [ 4.93813257e-03  1.52542921e+00  1.46234038e+00]\n",
      "  [-9.98483974e-04  5.24718892e-01  8.85091528e-04]\n",
      "  [ 6.94866057e-01  6.37597262e-02  3.53207212e-01]]\n",
      "\n",
      " [[ 2.92607241e-01  1.57079633e+00  2.07248413e-09]\n",
      "  [ 5.47283583e-01 -8.77565503e-02  1.02178574e+00]\n",
      "  [ 1.35592961e-01  2.02195229e-01  1.10755319e-01]\n",
      "  [ 1.90081703e-01  1.57062681e+00 -2.87499125e-05]\n",
      "  [ 1.07410893e+00 -2.34925572e-07  4.96687498e-01]\n",
      "  [ 5.05828647e-01 -1.12010129e-06  1.06496775e+00]\n",
      "  [ 1.00010374e+00  1.02249673e-01  1.09275735e+00]]]\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate the probability distribution over the basis states we first\n",
    "take `n_shots` samples and then compute the relative frequency of each\n",
    "outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_samples = prepare_and_sample(best_weights)\n",
    "raw_samples = prepare_and_sample(w)\n",
    "\n",
    "# convert the raw samples (bit strings) into integers and count them\n",
    "samples = []\n",
    "for sam in raw_samples:\n",
    "    samples.append(int(\"\".join(str(bs) for bs in sam), base=2))\n",
    "\n",
    "q_probs = np.bincount(samples) / n_shots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison\n",
    "==========\n",
    "\n",
    "Let us print the classical result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_n^2 =\n",
      " [0.00527872 0.00527872 0.00527872 0.00527872 0.00527872 0.00527872\n",
      " 0.00527872 0.00527872 0.00527872 0.00527872 0.00527872 0.00527872\n",
      " 0.00527872 0.00527872 0.00527872 0.00527872 0.00527872 0.00527872\n",
      " 0.00527872 0.00527872 0.00527872 0.00527872 0.00527872 0.00527872\n",
      " 0.00527872 0.00527872 0.00527872 0.00527872 0.00527872 0.00527872\n",
      " 0.00527872 0.00527872 0.01034628 0.01034628 0.01034628 0.01034628\n",
      " 0.01034628 0.01034628 0.01034628 0.01034628 0.01034628 0.01034628\n",
      " 0.01034628 0.01034628 0.01034628 0.01034628 0.01034628 0.01034628\n",
      " 0.01034628 0.01034628 0.01034628 0.01034628 0.01034628 0.01034628\n",
      " 0.01034628 0.01034628 0.01034628 0.01034628 0.01034628 0.01034628\n",
      " 0.01034628 0.01034628 0.01034628 0.01034628 0.00527872 0.00527872\n",
      " 0.00527872 0.00527872 0.00527872 0.00527872 0.00527872 0.00527872\n",
      " 0.00527872 0.00527872 0.00527872 0.00527872 0.00527872 0.00527872\n",
      " 0.00527872 0.00527872 0.00527872 0.00527872 0.00527872 0.00527872\n",
      " 0.00527872 0.00527872 0.00527872 0.00527872 0.00527872 0.00527872\n",
      " 0.00527872 0.00527872 0.00527872 0.00527872 0.00527872 0.00527872\n",
      " 0.01034628 0.01034628 0.01034628 0.01034628 0.01034628 0.01034628\n",
      " 0.01034628 0.01034628 0.01034628 0.01034628 0.01034628 0.01034628\n",
      " 0.01034628 0.01034628 0.01034628 0.01034628 0.01034628 0.01034628\n",
      " 0.01034628 0.01034628 0.01034628 0.01034628 0.01034628 0.01034628\n",
      " 0.01034628 0.01034628 0.01034628 0.01034628 0.01034628 0.01034628\n",
      " 0.01034628 0.01034628]\n"
     ]
    }
   ],
   "source": [
    "print(\"x_n^2 =\\n\", c_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous probabilities should match the following quantum state\n",
    "probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|<x|n>|^2=\n",
      " [0.014826 0.015117 0.014852 0.015274 0.014955 0.015472 0.015089 0.015255\n",
      " 0.015053 0.015134 0.014887 0.015097 0.014834 0.015307 0.014904 0.015164\n",
      " 0.015155 0.015233 0.015009 0.015338 0.01472  0.015052 0.014839 0.015218\n",
      " 0.015017 0.015209 0.014904 0.01532  0.015166 0.015166 0.014803 0.015287\n",
      " 0.000532 0.000498 0.000447 0.000531 0.000492 0.000526 0.000514 0.000544\n",
      " 0.00053  0.000546 0.000488 0.000495 0.000521 0.000546 0.000488 0.000554\n",
      " 0.000515 0.000518 0.000511 0.000559 0.000545 0.000512 0.000495 0.000543\n",
      " 0.000506 0.000561 0.000499 0.000524 0.000482 0.000506 0.000499 0.000515\n",
      " 0.014883 0.015109 0.015208 0.015528 0.014932 0.015377 0.015095 0.0151\n",
      " 0.014903 0.015068 0.015078 0.015167 0.015074 0.015102 0.01485  0.015175\n",
      " 0.014891 0.015357 0.014961 0.01546  0.014876 0.015432 0.015186 0.015452\n",
      " 0.014896 0.015382 0.014848 0.015211 0.015001 0.015351 0.014936 0.015253\n",
      " 0.000515 0.000526 0.000498 0.000539 0.000487 0.000533 0.000508 0.000522\n",
      " 0.000509 0.000527 0.000484 0.000573 0.000519 0.000501 0.000479 0.000528\n",
      " 0.000542 0.00057  0.000472 0.000517 0.000532 0.000547 0.000511 0.00052\n",
      " 0.000514 0.000532 0.000505 0.000513 0.000521 0.000519 0.000523 0.000574]\n"
     ]
    }
   ],
   "source": [
    "print(\"|<x|n>|^2=\\n\", q_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us graphically visualize both distributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 4))\n",
    "\n",
    "ax1.bar(np.arange(0, 2 ** n_qubits), c_probs, color=\"blue\")\n",
    "ax1.set_xlim(-0.5, 2 ** n_qubits - 0.5)\n",
    "ax1.set_xlabel(\"Vector space basis\")\n",
    "ax1.set_title(\"Classical probabilities\")\n",
    "\n",
    "ax2.bar(np.arange(0, 2 ** n_qubits), q_probs, color=\"green\")\n",
    "ax2.set_xlim(-0.5, 2 ** n_qubits - 0.5)\n",
    "ax2.set_xlabel(\"Hilbert space basis\")\n",
    "ax2.set_title(\"Quantum probabilities\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "==========\n",
    "\n",
    "1.  Carlos Bravo-Prieto, Ryan LaRose, Marco Cerezo, Yigit Subasi, Lukasz\n",
    "    Cincio, Patrick J. Coles. \\\"Variational Quantum Linear Solver: A\n",
    "    Hybrid Algorithm for Linear Systems.\\\"\n",
    "    [arXiv:1909.05820](https://arxiv.org/abs/1909.05820), 2019.\n",
    "\n",
    "About the author\n",
    "================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
